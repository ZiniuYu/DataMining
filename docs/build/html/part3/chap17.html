

<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" />
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  
  <title>Chapter 17 Clustering Validation &mdash; DataMining  documentation</title>
  

  
  <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />

  
  

  
  

  

  
  <!--[if lt IE 9]>
    <script src="../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
        <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
        <script src="../_static/jquery.js"></script>
        <script src="../_static/underscore.js"></script>
        <script src="../_static/doctools.js"></script>
        <script async="async" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    
    <script type="text/javascript" src="../_static/js/theme.js"></script>

    
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="prev" title="Chapter 16 Spectral and Graph Clustering" href="chap16.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="../index.html" class="icon icon-home"> DataMining
          

          
          </a>

          
            
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        
        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <p class="caption" role="heading"><span class="caption-text">Contents:</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../part1/index1.html">Part 1 Data Analysis Foundations</a></li>
<li class="toctree-l1 current"><a class="reference internal" href="index3.html">Part 3 Clustering</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="chap13.html">Chapter 13 Representative-based Clustering</a></li>
<li class="toctree-l2"><a class="reference internal" href="chap14.html">Chapter 14 Hierarchical Clustering</a></li>
<li class="toctree-l2"><a class="reference internal" href="chap15.html">Chapter 15 Density-based Clustering</a></li>
<li class="toctree-l2"><a class="reference internal" href="chap16.html">Chapter 16 Spectral and Graph Clustering</a></li>
<li class="toctree-l2 current"><a class="current reference internal" href="#">Chapter 17 Clustering Validation</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#external-measures">17.1 External Measures</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#matching-based-measures">17.1.1 Matching Based Measures</a></li>
<li class="toctree-l4"><a class="reference internal" href="#entropy-based-measures">17.1.2 Entropy-based Measures</a></li>
<li class="toctree-l4"><a class="reference internal" href="#pairwise-measures">17.1.3 Pairwise Measures</a></li>
<li class="toctree-l4"><a class="reference internal" href="#correlation-measures">17.1.4 Correlation Measures</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#internal-measures">17.2 Internal Measures</a></li>
<li class="toctree-l3"><a class="reference internal" href="#relative-measures">17.3 Relative Measures</a></li>
</ul>
</li>
</ul>
</li>
</ul>

            
          
        </div>
        
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">DataMining</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          

















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="../index.html" class="icon icon-home"></a> &raquo;</li>
        
          <li><a href="index3.html">Part 3 Clustering</a> &raquo;</li>
        
      <li>Chapter 17 Clustering Validation</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
          
            <a href="../_sources/part3/chap17.rst.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <div class="math notranslate nohighlight">
\[ \begin{align}\begin{aligned}\newcommand{\bs}{\boldsymbol}
\newcommand{\dp}{\displaystyle}
\newcommand{\rm}{\mathrm}
\newcommand{\cl}{\mathcal}
\newcommand{\pd}{\partial}\\\newcommand{\cd}{\cdot}
\newcommand{\cds}{\cdots}
\newcommand{\dds}{\ddots}
\newcommand{\lv}{\lVert}
\newcommand{\ol}{\overline}
\newcommand{\ra}{\rightarrow}
\newcommand{\rv}{\rVert}
\newcommand{\seq}{\subseteq}
\newcommand{\vds}{\vdots}
\newcommand{\wh}{\widehat}\\\newcommand{\0}{\boldsymbol{0}}
\newcommand{\1}{\boldsymbol{1}}
\newcommand{\a}{\boldsymbol{\mathrm{a}}}
\newcommand{\b}{\boldsymbol{\mathrm{b}}}
\newcommand{\c}{\boldsymbol{\mathrm{c}}}
\newcommand{\e}{\boldsymbol{\mathrm{e}}}
\newcommand{\f}{\boldsymbol{\mathrm{f}}}
\newcommand{\g}{\boldsymbol{\mathrm{g}}}
\newcommand{\i}{\boldsymbol{\mathrm{i}}}
\newcommand{\j}{\boldsymbol{j}}
\newcommand{\n}{\boldsymbol{\mathrm{n}}}
\newcommand{\p}{\boldsymbol{\mathrm{p}}}
\newcommand{\q}{\boldsymbol{\mathrm{q}}}
\newcommand{\r}{\boldsymbol{\mathrm{r}}}
\newcommand{\u}{\boldsymbol{\mathrm{u}}}
\newcommand{\v}{\boldsymbol{\mathrm{v}}}
\newcommand{\w}{\boldsymbol{\mathrm{w}}}
\newcommand{\x}{\boldsymbol{\mathrm{x}}}
\newcommand{\y}{\boldsymbol{\mathrm{y}}}
\newcommand{\z}{\boldsymbol{\mathrm{z}}}\\\newcommand{\A}{\boldsymbol{\mathrm{A}}}
\newcommand{\B}{\boldsymbol{B}}
\newcommand{\C}{\boldsymbol{C}}
\newcommand{\D}{\boldsymbol{\mathrm{D}}}
\newcommand{\I}{\boldsymbol{\mathrm{I}}}
\newcommand{\K}{\boldsymbol{\mathrm{K}}}
\newcommand{\M}{\boldsymbol{\mathrm{M}}}
\newcommand{\N}{\boldsymbol{\mathrm{N}}}
\newcommand{\P}{\boldsymbol{\mathrm{P}}}
\newcommand{\S}{\boldsymbol{\mathrm{S}}}
\newcommand{\U}{\boldsymbol{\mathrm{U}}}
\newcommand{\W}{\boldsymbol{\mathrm{W}}}
\newcommand{\X}{\boldsymbol{\mathrm{X}}}\\\newcommand{\R}{\mathbb{R}}\\\newcommand{\ld}{\lambda}
\newcommand{\Ld}{\boldsymbol{\mathrm{\Lambda}}}
\newcommand{\sg}{\sigma}
\newcommand{\Sg}{\boldsymbol{\mathrm{\Sigma}}}
\newcommand{\th}{\theta}\\\newcommand{\mmu}{\boldsymbol{\mu}}
\newcommand{\ppi}{\boldsymbol{\pi}}
\newcommand{\CC}{\mathcal{C}}
\newcommand{\TT}{\mathcal{T}}\\
\newcommand{\bb}{\begin{bmatrix}}
\newcommand{\eb}{\end{bmatrix}}
\newcommand{\bp}{\begin{pmatrix}}
\newcommand{\ep}{\end{pmatrix}}
\newcommand{\bv}{\begin{vmatrix}}
\newcommand{\ev}{\end{vmatrix}}\\\newcommand{\im}{^{-1}}
\newcommand{\pr}{^{\prime}}
\newcommand{\ppr}{^{\prime\prime}}\end{aligned}\end{align} \]</div>
<div class="section" id="chapter-17-clustering-validation">
<h1>Chapter 17 Clustering Validation<a class="headerlink" href="#chapter-17-clustering-validation" title="Permalink to this headline">¶</a></h1>
<p>Cluster validation and assessment encompasses three main tasks: <em>clustering</em>
<em>evaluation</em> seeks to asses the goodness or quality of the clustering,
<em>clustering stability</em> seeks to understand the sensitivity of the clustering
result to various algorithmic parameters, and <em>clustering tendency</em> assesses the
suitability of applying clustering in the first place.</p>
<p><strong>External</strong>: external validation measures employ criteria that are not inherent to the dataset.</p>
<p><strong>Internal</strong>: Internal validation measures employ critieria that are derived from the data itself.</p>
<p><strong>Relative</strong>: Relative validation measures aim to directly compare different
clusterings, usually those obtained via different parameter settings for the
same algorithm.</p>
<div class="section" id="external-measures">
<h2>17.1 External Measures<a class="headerlink" href="#external-measures" title="Permalink to this headline">¶</a></h2>
<p>External measures assume that the correct or ground-truth clustering is known a <em>priori</em>.
The true cluster labels play the role of external information that is used to evaluate a given clustering.</p>
<p>Let <span class="math notranslate nohighlight">\(\D\)</span> be a dataset consisting of <span class="math notranslate nohighlight">\(n\)</span> points <span class="math notranslate nohighlight">\(\x_i\)</span> in a
<em>d</em>-dimensional space, partitioned into <span class="math notranslate nohighlight">\(k\)</span> clusters.
Let <span class="math notranslate nohighlight">\(y_i\in\{1,2,\cds,k\}\)</span> denote the ground-truth cluster membership or label information for each point.
The ground-truth clustering is given as <span class="math notranslate nohighlight">\(\cl{T}=\{T_1,T_2,\cds,T_k\}\)</span>,
where the cluster <span class="math notranslate nohighlight">\(T_j\)</span> consists of all the points with label <span class="math notranslate nohighlight">\(j\)</span>,
i.e., <span class="math notranslate nohighlight">\(T_j=\{\x_i\in\D|y_i=j\}\)</span>.
Also, let <span class="math notranslate nohighlight">\(\cl{C}=\{C_1,\cds,C_r\}\)</span> dentoe a clustering of the same
dataset into <span class="math notranslate nohighlight">\(r\)</span> clusters, obtained via some clustering algorithm, and let
<span class="math notranslate nohighlight">\(\hat{y_i}\in\{1,2,\cds,r\}\)</span> denote the cluster label for <span class="math notranslate nohighlight">\(\x_i\)</span>.</p>
<p>External evaluation measures try capture the extent to which points from the
same partition appear in the same cluster, and the extent to which points from
different partitions are grouped in different clusters.
All of the external measures rely on the <span class="math notranslate nohighlight">\(r\times k\)</span> <em>contingency tabel</em>
<span class="math notranslate nohighlight">\(\N\)</span> that is induced by a clustering <span class="math notranslate nohighlight">\(\cl{C}\)</span> and the ground-truth
partitioning <span class="math notranslate nohighlight">\(\cl{T}\)</span>, defined as follows</p>
<div class="math notranslate nohighlight">
\[\N(i,j)=n_{ij}=|C_i\cap T_j|\]</div>
<p>In other words, the count <span class="math notranslate nohighlight">\(n_{ij}\)</span> denotes the number of points that are
common to cluster <span class="math notranslate nohighlight">\(C_i\)</span> and ground-truth partition <span class="math notranslate nohighlight">\(T_j\)</span>.</p>
<div class="section" id="matching-based-measures">
<h3>17.1.1 Matching Based Measures<a class="headerlink" href="#matching-based-measures" title="Permalink to this headline">¶</a></h3>
<p><strong>Purity</strong></p>
<div class="math notranslate nohighlight">
\[purity_i=\frac{1}{n_i}\max_{j=1}^k\{n_{ij}\}\]</div>
<p>The purity of clustering <span class="math notranslate nohighlight">\(\cl{C}\)</span> is defined as the weighted sum of the clusterwise purity values:</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p><span class="math notranslate nohighlight">\(\dp purity=\sum_{i=1}^r\frac{n_i}{n}purity_i=\frac{1}{n}\sum_{i=1}^r\max_{j=1}^k\{n_{ij}\}\)</span></p>
</div>
<p>The larger the purity of <span class="math notranslate nohighlight">\(\cl{C}\)</span>, the better the agreement with the groundtruth.
The maximum value of purity is 1, when each cluster comprises points from only one partition.
When <span class="math notranslate nohighlight">\(r=k\)</span>, a purity value of 1 indicates a perfect clustering, with a
one-to-one correspondence between the clsuters and partitions.
However, purity can be 1 even for <span class="math notranslate nohighlight">\(r&gt;k\)</span>, when each of the clusters is a subset of a ground-truth partition.
When <span class="math notranslate nohighlight">\(r&lt;k\)</span>, purity can never by 1, because at least one cluster must contain points from more than one partition.</p>
<p><strong>Maximum Matching</strong></p>
<p>The maximum matching measure selects the mapping between clusters and
partitions, such that the sum of the number of common points (<span class="math notranslate nohighlight">\(n_{ij}\)</span>) is
maximized, provided that onlyl one cluster can match with a given partition.</p>
<p>Formally, we treat the contigency table as a complete weighted bipartite graph
<span class="math notranslate nohighlight">\(G=(V,E)\)</span>, where each partition and cluster is a node, that is,
<span class="math notranslate nohighlight">\(V=\cl{C}\cup\cl{T}\)</span>, and there exists an edge <span class="math notranslate nohighlight">\((C_i,T_j)\in E\)</span>,
with weight <span class="math notranslate nohighlight">\(w(C_i,T_i)=n_{ij}\)</span>, for all <span class="math notranslate nohighlight">\(C_i\in\cl{C}\)</span> and
<span class="math notranslate nohighlight">\(T_j\in\cl{T}\)</span>.
A <em>matching</em> <span class="math notranslate nohighlight">\(M\)</span> in <span class="math notranslate nohighlight">\(G\)</span> is a subset of <span class="math notranslate nohighlight">\(E\)</span>, such that the
edges in <span class="math notranslate nohighlight">\(M\)</span> are pairwise nonadjacent, that is, they do not have a common
vertex.
The maximum matching measure is defined as the <em>maximum weight matching</em> in <span class="math notranslate nohighlight">\(G\)</span>:</p>
<div class="math notranslate nohighlight">
\[match=\arg\max_M\bigg\{\frac{w(M)}{n}\bigg\}\]</div>
<p>where the weight of a matching <span class="math notranslate nohighlight">\(M\)</span> is simply the sum of all the edge
weights in <span class="math notranslate nohighlight">\(M\)</span>, given as <span class="math notranslate nohighlight">\(w(M)=\sum)_{e\in M}w(e)\)</span>.
The maximum matching can be computed in time
<span class="math notranslate nohighlight">\(O(|V|^2\cd|E|)=O((r+k)^2rk)\)</span>, which is equivalent to <span class="math notranslate nohighlight">\(O(k^4)\)</span> if
<span class="math notranslate nohighlight">\(r=O(k)\)</span>.</p>
<p><strong>F-Measure</strong></p>
<p>Given cluster <span class="math notranslate nohighlight">\(C_i\)</span>, let <span class="math notranslate nohighlight">\(j_i\)</span> denote the partition that contains
the maximum number of points from <span class="math notranslate nohighlight">\(C_i\)</span>, that is,
<span class="math notranslate nohighlight">\(j_i=\max_{j=1}^k\{n_{ij}\}\)</span>.
The <em>precision</em> of a cluster <span class="math notranslate nohighlight">\(C_i\)</span> is the same as its purity:</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p><span class="math notranslate nohighlight">\(\dp prec_i=\frac{1}{n_i}\max_{j=1}^k\{n_{ij}\}=\frac{n_{ij_i}}{n_i}\)</span></p>
</div>
<p>It measures the fraction of points in <span class="math notranslate nohighlight">\(C_i\)</span> from the majority partition <span class="math notranslate nohighlight">\(T_{j_i}\)</span>.</p>
<p>The <em>recall</em> of cluster <span class="math notranslate nohighlight">\(C_i\)</span> is defined as</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p><span class="math notranslate nohighlight">\(\dp recall_i=\frac{n_{ij_i}}{|T_{j_{i}}|}=\frac{n_{ij_i}}{m_{j_i}}\)</span></p>
</div>
<p>where <span class="math notranslate nohighlight">\(m_{j_i}=|T_{j_i}|\)</span>.
It measures the fraction of point in partition <span class="math notranslate nohighlight">\(T_{j_i}\)</span> shared in common with cluster <span class="math notranslate nohighlight">\(C_i\)</span>.</p>
<p>The F-measure is the harmonic mean of the precision and recall values for each cluster.
The F-measure for cluster <span class="math notranslate nohighlight">\(C_i\)</span> is therefore given as</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p><span class="math notranslate nohighlight">\(\dp F_i=\frac{2}{\frac{1}{prec_i}+\frac{1}{recall_i}}=\frac{2\cd prec_i\cd recall_i}{prec_i+recall_i}\)</span>
<span class="math notranslate nohighlight">\(\dp=\frac{2n_{ij_i}}{n_i+m_{j_i}}\)</span></p>
</div>
<p>The F-measures for the clustering <span class="math notranslate nohighlight">\(\cl{C}\)</span> is the mean of clusterwise F-measure values:</p>
<div class="math notranslate nohighlight">
\[F=\frac{1}{r}\sum_{i=1}^rF_i\]</div>
<p>F-measure thus tries to balance the precision and recall values across all the clusters.
For a perfect clustering, when <span class="math notranslate nohighlight">\(r=k\)</span>, the maximum value of the F-measure is 1.</p>
</div>
<div class="section" id="entropy-based-measures">
<h3>17.1.2 Entropy-based Measures<a class="headerlink" href="#entropy-based-measures" title="Permalink to this headline">¶</a></h3>
<p><strong>Conditional Entropy</strong></p>
<p>The entropy of a clustering <span class="math notranslate nohighlight">\(\cl{C}\)</span> is defined as</p>
<div class="math notranslate nohighlight">
\[H(\cl{C})=-\sum_{i=1}^rp_{C_i}\log p_{C_i}\]</div>
<p>where <span class="math notranslate nohighlight">\(p_{C_i}=\frac{n_i}{n}\)</span> is the probability of cluster <span class="math notranslate nohighlight">\(C_i\)</span>.
The entropy of the partitioning <span class="math notranslate nohighlight">\(\cl{T}\)</span> is defined as</p>
<div class="math notranslate nohighlight">
\[H(\cl{T})=-\sum_{j=1}^kp_{T_j}\log p_{T_j}\]</div>
<p>where <span class="math notranslate nohighlight">\(p_{T_j}=\frac{m_j}{n}\)</span> is the probability of partition <span class="math notranslate nohighlight">\(T_j\)</span>.</p>
<p>The cluster-specific entropy of <span class="math notranslate nohighlight">\(\cl{T}\)</span>, that is, the conditional entropy
of <span class="math notranslate nohighlight">\(\cl{T}\)</span> with respect to cluster <span class="math notranslate nohighlight">\(C_i\)</span> is defined as</p>
<div class="math notranslate nohighlight">
\[H(\cl{T}|C_i)=-\sum_{j=1}^k\bigg(\frac{n_{ij}}{n_i}\bigg)\log\bigg(\frac{n_{ij}}{n_i}\bigg)\]</div>
<p>The conditional entropy of <span class="math notranslate nohighlight">\(\cl{T}\)</span> given clustering <span class="math notranslate nohighlight">\(\cl{C}\)</span> is then defined as the weighted sum:</p>
<div class="math notranslate nohighlight">
\[H(\cl{T}|\cl{C})=\sum_{i=1}^r\frac{n_i}{n}H(\cl{T}|C_i)=
\sum_{i=1}^r\sum_{j=1}^k\frac{n_{ij}}{n}\log\bigg(\frac{n_{ij}}{n_i}\bigg)\]</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p><span class="math notranslate nohighlight">\(\dp=-\sum_{i=1}^r\sum_{j=1}^kp_{ij}\log\bigg(\frac{p_{ij}}{p_{C_i}}\bigg)\)</span></p>
</div>
<p>where <span class="math notranslate nohighlight">\(p_{ij}=\frac{n_{ij}}{n}\)</span> is the probability that a point in cluster
<span class="math notranslate nohighlight">\(i\)</span> also belongs to partition <span class="math notranslate nohighlight">\(j\)</span>.
For a perfect clustering, the conditional entropy value is zero, whereas the
worst possible conditional entropy value is <span class="math notranslate nohighlight">\(\log k\)</span>.</p>
<div class="math notranslate nohighlight">
\[ \begin{align}\begin{aligned}H(\cl{T}|\cl{C})&amp;=-\sum_{i=1}^r\sum_{j=1}^kp_{ij}(\log p_{ij}-\log p_{C_i})\\&amp;=-\bigg(\sum_{i=1}^r\sum_{j=1}^kp_{ij}\log p_{ij}\bigg)+\sum_{i=1}^r\bigg(\log p_{C_i}\sum_{j=1}^kp_{ij}\bigg)\\&amp;=-\sum_{i=1}^r\sum_{j=1}^kp_{ij}\log p_{ij}+\sum_{i=1}^rp_{C_i}\log p_{C_i}\\&amp;=H(\cl{C},\cl{T})-H(\cl{C})\end{aligned}\end{align} \]</div>
<p>where <span class="math notranslate nohighlight">\(H(\cl{C},\cl{T})=-\sum_{i=1}^r\sum_{j=1}^kp_{ij}\log p_{ij}\)</span> is the
joint entropy of <span class="math notranslate nohighlight">\(\cl{C}\)</span> and <span class="math notranslate nohighlight">\(\cl{T}\)</span>.
The conditional entropy <span class="math notranslate nohighlight">\(H(\cl{T}|\cl{C})\)</span> thus measures the remaining
entropy of <span class="math notranslate nohighlight">\(\cl{T}\)</span> given the clustering <span class="math notranslate nohighlight">\(\cl{C}\)</span>.
In particular, <span class="math notranslate nohighlight">\(H(\cl{T}|\cl{C})=0\)</span> if and only if <span class="math notranslate nohighlight">\(\cl{T}\)</span> is
completely determined by <span class="math notranslate nohighlight">\(\cl{C}\)</span>, corresponding to the ideal clustering.
On the other hand, if <span class="math notranslate nohighlight">\(\cl{C}\)</span> and <span class="math notranslate nohighlight">\(\cl{T}\)</span> are independent of each
other, then <span class="math notranslate nohighlight">\(H(\cl{T}|\cl{C})=H(\cl{T})\)</span>, which means that <span class="math notranslate nohighlight">\(\cl{C}\)</span>
provides no information about <span class="math notranslate nohighlight">\(\cl{T}\)</span>.</p>
<p><strong>Normalized Mutual Information</strong></p>
<p>The <em>mutual information</em> tries to quantify the amount of shared information
between the clustering <span class="math notranslate nohighlight">\(\cl{C}\)</span> and partitioning <span class="math notranslate nohighlight">\(\cl{T}\)</span>, and it is
defined as</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p><span class="math notranslate nohighlight">\(\dp I(\cl{C},\cl{T})=\sum_{i=1}^r\sum_{j=1}^kp_{ij}\log\bigg(\frac{p_{ij}}{p_{C_i}\cd p_{T_j}}\bigg)\)</span></p>
</div>
<p>It measures the dependence between the observed joint probability <span class="math notranslate nohighlight">\(p_{ij}\)</span>
of <span class="math notranslate nohighlight">\(\cl{C}\)</span> and <span class="math notranslate nohighlight">\(\cl{T}\)</span>, and the expected joint probability
<span class="math notranslate nohighlight">\(p_{C_i}\cd p_{T_j}\)</span> under the independence assumption.
When <span class="math notranslate nohighlight">\(\cl{C}\)</span> and <span class="math notranslate nohighlight">\(\cl{T}\)</span> are independent then
<span class="math notranslate nohighlight">\(p_{ij}=p_{C_i}\cd p_{T_j}\)</span>, and thus <span class="math notranslate nohighlight">\(T(\cl{C},\cl{T})=0\)</span>.</p>
<div class="math notranslate nohighlight">
\[ \begin{align}\begin{aligned}I(\cl{C},\cl{T})=H(\cl{T})-H(\cl{T}|\cl{C})\\I(\cl{C},\cl{T})=H(\cl{C})-H(\cl{C}|\cl{T})\end{aligned}\end{align} \]</div>
<p>Finally, because <span class="math notranslate nohighlight">\(H(\CC,\TT)\geq 0\)</span> and <span class="math notranslate nohighlight">\(H(\TT|\CC)\geq 0\)</span>, we have
the inequalities <span class="math notranslate nohighlight">\(I(\CC,\TT)\leq H(\CC)\)</span> and
<span class="math notranslate nohighlight">\(I(\CC,\TT)\leq H(\TT)\)</span>.</p>
<p>The <em>normalized mutual information</em> (NMI) is defined as the geometric mean of two ratios:</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p><span class="math notranslate nohighlight">\(\dp NMI(\CC,\TT)=\sqrt{\frac{I(\CC,\TT)}{H(\CC)}\cd\frac{I(\CC,\TT)}{H(\TT)}}=\)</span>
<span class="math notranslate nohighlight">\(\dp\frac{I(\CC,\TT)}{\sqrt{H(\CC)\cd H(\TT)}}\)</span></p>
</div>
<p>The NMI value lies in the range <span class="math notranslate nohighlight">\([0, 1]\)</span>.
Values close to 1 indicate a good clustering.</p>
<p><strong>Variation of Information</strong></p>
<div class="math notranslate nohighlight">
\[ \begin{align}\begin{aligned}VI(\CC,\TT)&amp;=(H(\TT)-I(\CC,\TT))+(H(\CC)-I(\CC,\TT))\\&amp;=H(\TT)+H(\CC)-2I(\CC,\TT)\end{aligned}\end{align} \]</div>
<p>Variation of information (VI) is zero only when <span class="math notranslate nohighlight">\(\CC\)</span> and <span class="math notranslate nohighlight">\(\TT\)</span> are identical.
Thus the lower the VI value the better the clustering <span class="math notranslate nohighlight">\(\CC\)</span>.</p>
<div class="math notranslate nohighlight">
\[VI(\CC,\TT)=H(\TT|\CC)+H(\CC|\TT)\]</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p><span class="math notranslate nohighlight">\(VI(\CC,\TT)=2H(\TT,\CC)-H(\TT)-H(\CC)\)</span></p>
</div>
</div>
<div class="section" id="pairwise-measures">
<h3>17.1.3 Pairwise Measures<a class="headerlink" href="#pairwise-measures" title="Permalink to this headline">¶</a></h3>
</div>
<div class="section" id="correlation-measures">
<h3>17.1.4 Correlation Measures<a class="headerlink" href="#correlation-measures" title="Permalink to this headline">¶</a></h3>
</div>
</div>
<div class="section" id="internal-measures">
<h2>17.2 Internal Measures<a class="headerlink" href="#internal-measures" title="Permalink to this headline">¶</a></h2>
</div>
<div class="section" id="relative-measures">
<h2>17.3 Relative Measures<a class="headerlink" href="#relative-measures" title="Permalink to this headline">¶</a></h2>
</div>
</div>


           </div>
           
          </div>
          <footer>
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
        <a href="chap16.html" class="btn btn-neutral float-left" title="Chapter 16 Spectral and Graph Clustering" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>
        &#169; Copyright 2021, Ziniu Yu.

    </p>
  </div>
    
    
    
    Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    
    provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>
        </div>
      </div>

    </section>

  </div>
  

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
   

</body>
</html>